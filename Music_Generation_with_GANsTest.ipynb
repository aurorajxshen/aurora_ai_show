{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music Generation with GANs.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aurorajxshen/aurora_ai_show/blob/main/Music_Generation_with_GANsTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgXVFl5SmZvC"
      },
      "source": [
        "# Generating Music with GANs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0mic3ibwJcb",
        "outputId": "f471e3ad-ed55-4229-a519-c217c6f6ae78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip uninstall pip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ENB7RZ5wQb0",
        "outputId": "b7f9bfdd-2f22-4057-9d0d-041938cd8526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pip 24.1.2\n",
            "Uninstalling pip-24.1.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/pip\n",
            "    /usr/local/bin/pip3\n",
            "    /usr/local/bin/pip3.10\n",
            "    /usr/local/lib/python3.10/dist-packages/pip-24.1.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/pip/*\n",
            "Proceed (Y/n)? t\n",
            "Your response ('t') was not one of the expected responses: y, n, \n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled pip-24.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --remove python /usr/local/bin/python\n",
        "!sudo apt install python3.6\n",
        "!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.6 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw53ED50wf4E",
        "outputId": "b3d0a3ca-9a0a-4b6c-d54d-a679b8c7d50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package python3.6\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mCouldn't find any package by glob 'python3.6'\u001b[0m\n",
            "update-alternatives: error: alternative path /usr/bin/python3.6 doesn't exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAk_-6QOwwM2",
        "outputId": "b603121d-4059-48b8-93ae-f7aa84a4a197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package python3.6\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mCouldn't find any package by glob 'python3.6'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z2IRbHqxVtX",
        "outputId": "84bb8519-a9a1-4933-a0da-6eee8ae7c0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbnAHJ0Wx2q-",
        "outputId": "1a5b9393-abff-4738-f58c-979d7d1b4c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package python3.6\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mCouldn't find any package by glob 'python3.6'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zEqGP-3ygj8",
        "outputId": "02519c0f-f908-428a-8b41-b211eb0c0da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0] on linux\n",
            "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
            ">>> EXIT\n",
            "Traceback (most recent call last):\n",
            "  File \"<stdin>\", line 1, in <module>\n",
            "NameError: name 'EXIT' is not defined\n",
            ">>> EXI()\n",
            "Traceback (most recent call last):\n",
            "  File \"<stdin>\", line 1, in <module>\n",
            "NameError: name 'EXI' is not defined\n",
            ">>> EXIT()\n",
            "Traceback (most recent call last):\n",
            "  File \"<stdin>\", line 1, in <module>\n",
            "NameError: name 'EXIT' is not defined\n",
            ">>> \n",
            "\n",
            "KeyboardInterrupt\n",
            ">>> ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -b -p /usr/local/miniconda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQdg_-a63Y3Z",
        "outputId": "efb949e1-ea01-4e2a-c962-6139eec846d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-24 04:12:34--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147784736 (141M) [application/octet-stream]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>] 140.94M   137MB/s    in 1.0s    \n",
            "\n",
            "2024-12-24 04:12:35 (137 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [147784736/147784736]\n",
            "\n",
            "PREFIX=/usr/local/miniconda\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local/miniconda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/usr/local/miniconda/bin:$PATH\"\n"
      ],
      "metadata": {
        "id": "NGAEYPBt3jMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PATH\"] += \":/usr/local/miniconda/bin\""
      ],
      "metadata": {
        "id": "pC2lYQty4-Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djMU4FVL5bXP",
        "outputId": "6061eca3-4786-403f-d7b8-c75ac851da44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 24.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n py36 python=3.6 -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsm4luGS4A9A",
        "outputId": "50162a5e-06ad-4c8d-edfa-8cee069c7b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/miniconda/envs/py36\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         139 KB\n",
            "    libffi-3.3                 |       he6710b0_2          50 KB\n",
            "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         1.8 MB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    setuptools-58.0.4          |   py36h06a4308_0         788 KB\n",
            "    wheel-0.37.1               |     pyhd3eb1b0_0          33 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        39.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.11.26-h06a4308_0 \n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0 \n",
            "  pip                pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0 \n",
            "  python             pkgs/main/linux-64::python-3.6.13-h12debd9_1 \n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-58.0.4-py36h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0 \n",
            "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.6.13        | 32.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "openssl-1.1.1w       | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pip-21.2.2           | 1.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "setuptools-58.0.4    | 788 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "certifi-2021.5.30    | 139 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.37.1         | 33 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "python-3.6.13        | 32.5 MB   | :   0% 0.000962067985804917/1 [00:00<01:46, 106.53s/it]\n",
            "\n",
            "pip-21.2.2           | 1.8 MB    | :   2% 0.017027361839753237/1 [00:00<00:05,  6.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "certifi-2021.5.30    | 139 KB    | :  23% 0.2299589459279273/1 [00:00<00:00,  2.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "setuptools-58.0.4    | 788 KB    | :   4% 0.04060506101044247/1 [00:00<00:02,  2.63s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "certifi-2021.5.30    | 139 KB    | : 100% 1.0/1 [00:00<00:00,  2.24it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "certifi-2021.5.30    | 139 KB    | : 100% 1.0/1 [00:00<00:00,  2.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | :  32% 0.3178705158799449/1 [00:00<00:00,  1.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00,  1.93it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :   9% 0.08706715271534499/1 [00:00<00:01,  1.98s/it]  \n",
            "openssl-1.1.1w       | 3.7 MB    | :  68% 0.6783254188791231/1 [00:00<00:00,  3.92it/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.37.1         | 33 KB     | :  49% 0.491583905907768/1 [00:00<00:00,  2.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.37.1         | 33 KB     | : 100% 1.0/1 [00:00<00:00,  2.29it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00,  1.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  4.88it/s]                 \u001b[A\u001b[A\n",
            "\n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.37.1         | 33 KB     | : 100% 1.0/1 [00:00<00:00,  2.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "python-3.6.13        | 32.5 MB   | :  70% 0.7042337656091993/1 [00:00<00:00,  1.78it/s] \n",
            "\n",
            "\n",
            "setuptools-58.0.4    | 788 KB    | : 100% 1.0/1 [00:00<00:00,  1.77it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :  89% 0.8884697848908409/1 [00:00<00:00,  1.80it/s]\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.92it/s]\u001b[A\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate py36\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /usr/local/miniconda/bin/activate py36"
      ],
      "metadata": {
        "id": "wbSvb5Tz6pBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/miniconda/envs/py36/bin/python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PURytlUX7Ar5",
        "outputId": "4286a6be-0832-410e-a6b8-e61a6a353245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.6.13 :: Anaconda, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda activate py36\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBL4dKF95qN_",
        "outputId": "4bf154b1-fcff-413b-f7bb-8c90532c7b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuEuSGE0587G",
        "outputId": "773a196b-93ed-4c78-faa6-6a007d7f6975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mArAbLs2mBhd"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeGaPSXNdqy-"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ_cVBuhk13r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc2bbbb-5bcb-4505-b048-8aa597828f5b"
      },
      "source": [
        "!pip3 install torch matplotlib tqdm livelossplot gdown \"pypianoroll>=1.0.2\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Collecting pypianoroll>=1.0.2\n",
            "  Downloading pypianoroll-1.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.6.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pypianoroll>=1.0.2) (1.13.1)\n",
            "Collecting pretty-midi>=0.2.8 (from pypianoroll>=1.0.2)\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mido>=1.1.16 (from pretty-midi>=0.2.8->pypianoroll>=1.0.2)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty-midi>=0.2.8->pypianoroll>=1.0.2) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2.2.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Downloading pypianoroll-1.0.4-py3-none-any.whl (26 kB)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty-midi\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592287 sha256=04e4da4c6b77283c1d1d7104e93636ac727d583991b5b17963cf6760290aa45e\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built pretty-midi\n",
            "Installing collected packages: mido, pretty-midi, pypianoroll, livelossplot\n",
            "Successfully installed livelossplot-0.5.5 mido-1.3.3 pretty-midi-0.2.10 pypianoroll-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn-74oKmdyF7"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOkT9h38krfZ"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from ipywidgets import interact, IntSlider\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "from tqdm import tqdm\n",
        "from livelossplot import PlotLosses\n",
        "from livelossplot.outputs import MatplotlibPlot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VyXuXFtoLxL"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA14sQ-YoTvW"
      },
      "source": [
        "# Data\n",
        "n_tracks = 5  # number of tracks\n",
        "n_pitches = 72  # number of pitches\n",
        "lowest_pitch = 24  # MIDI note number of the lowest pitch\n",
        "n_samples_per_song = 8  # number of samples to extract from each song in the datset\n",
        "n_measures = 4  # number of measures per sample\n",
        "beat_resolution = 4  # temporal resolution of a beat (in timestep)\n",
        "programs = [0, 0, 25, 33, 48]  # program number for each track\n",
        "is_drums = [True, False, False, False, False]  # drum indicator for each track\n",
        "track_names = ['Drums', 'Piano', 'Guitar', 'Bass', 'Strings']  # name of each track\n",
        "tempo = 100\n",
        "\n",
        "# Training\n",
        "batch_size = 16\n",
        "latent_dim = 128\n",
        "n_steps = 20000\n",
        "\n",
        "# Sampling\n",
        "sample_interval = 100  # interval to run the sampler (in step)\n",
        "n_samples = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F91IBYd8mr9f"
      },
      "source": [
        "measure_resolution = 4 * beat_resolution\n",
        "tempo_array = np.full((4 * 4 * measure_resolution, 1), tempo)\n",
        "assert 24 % beat_resolution == 0, (\n",
        "    \"beat_resolution must be a factor of 24 (the beat resolution used in \"\n",
        "    \"the source dataset).\"\n",
        ")\n",
        "assert len(programs) == len(is_drums) and len(programs) == len(track_names), (\n",
        "    \"Lengths of programs, is_drums and track_names must be the same.\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JyxQDtXfhbp"
      },
      "source": [
        "## Data Prepration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79jp0AoJep4X"
      },
      "source": [
        "### Download the Lakh Pianoroll Dataset (LPD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTdEEg2Xdnbt",
        "outputId": "40f7d4fb-a8d9-44c7-809e-32a61c732c71"
      },
      "source": [
        "!mkdir -p data\n",
        "\n",
        "# !gdown -O data/lpd_5_cleansed.tar.gz https://drive.google.com/uc?id=1yz0Ma-6cWTl6mhkrLnAVJ7RNzlQRypQ5\n",
        "# !gdown -O data/id_lists_amg.tar.gz https://drive.google.com/uc?id=1hp9b_g1hu_dkP4u8h46iqHeWMaUoI07R\n",
        "# !gdown -O data/id_lists_lastfm.tar.gz https://drive.google.com/uc?id=1mpsoxU2fU1AjKopkcQ8Q8V6wYmVPbnPO\n",
        "\n",
        "!gdown -O data/lpd_5_cleansed.tar.gz https://ucsdcloud-my.sharepoint.com/:u:/r/personal/h3dong_ucsd_edu/Documents/data/lpd/lpd_5/lpd_5_cleansed.tar.gz?csf=1&web=1&e=9c9fz4\n",
        "!gdown -O data/id_lists_amg.tar.gz https://drive.google.com/uc?id=1hp9b_g1hu_dkP4u8h46iqHeWMaUoI07R\n",
        "!gdown -O data/id_lists_lastfm.tar.gz https://drive.google.com/uc?id=1mpsoxU2fU1AjKopkcQ8Q8V6wYmVPbnPO\n",
        "\n",
        "!tar zxf data/lpd_5_cleansed.tar.gz -C data/\n",
        "!tar zxf data/id_lists_amg.tar.gz -C data/\n",
        "!tar zxf data/id_lists_lastfm.tar.gz -C data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1yz0Ma-6cWTl6mhkrLnAVJ7RNzlQRypQ5\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1hp9b_g1hu_dkP4u8h46iqHeWMaUoI07R\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1mpsoxU2fU1AjKopkcQ8Q8V6wYmVPbnPO\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "tar (child): data/lpd_5_cleansed.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n",
            "tar (child): data/id_lists_amg.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n",
            "tar (child): data/id_lists_lastfm.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoN6wcDDjIDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "171fb55b-2092-4895-b59a-6631584fe633"
      },
      "source": [
        "dataset_root = Path(\"data/lpd_5/lpd_5_cleansed/\")\n",
        "id_list = []\n",
        "for path in os.listdir(\"data/amg\"):\n",
        "    filepath = os.path.join(\"data/amg\", path)\n",
        "    if os.path.isfile(filepath):\n",
        "        with open(filepath) as f:\n",
        "            id_list.extend([line.rstrip() for line in f])\n",
        "id_list = list(set(id_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/amg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-56c0017bf4eb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/lpd_5/lpd_5_cleansed/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mid_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/amg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/amg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/amg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWDFp1pR5CQd"
      },
      "source": [
        "def msd_id_to_dirs(msd_id):\n",
        "    \"\"\"Given an MSD ID, generate the path prefix.\n",
        "    E.g. TRABCD12345678 -> A/B/C/TRABCD12345678\"\"\"\n",
        "    return os.path.join(msd_id[2], msd_id[3], msd_id[4], msd_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvn3WqbMfaiz"
      },
      "source": [
        "### Visualize an example of pianorolls in LPD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JPHTDHL54F0"
      },
      "source": [
        "song_dir = dataset_root / msd_id_to_dirs('TREVDFX128E07859E0') # 'TRQAOWZ128F93000A4', 'TREVDFX128E07859E0'\n",
        "multitrack = pypianoroll.load(song_dir / os.listdir(song_dir)[0])\n",
        "multitrack.trim(end=12 * 96)\n",
        "axs = multitrack.plot()\n",
        "plt.gcf().set_size_inches((16, 8))\n",
        "for ax in axs:\n",
        "    for x in range(96, 12 * 96, 96):\n",
        "        ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGRUCRm_CGej"
      },
      "source": [
        "### Collect training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPGrsycbhodh"
      },
      "source": [
        "data = []\n",
        "# Iterate over all the songs in the ID list\n",
        "for msd_id in tqdm(id_list):\n",
        "    # Load the multitrack as a pypianoroll.Multitrack instance\n",
        "    song_dir = dataset_root / msd_id_to_dirs(msd_id)\n",
        "    multitrack = pypianoroll.load(song_dir / os.listdir(song_dir)[0])\n",
        "    # Binarize the pianorolls\n",
        "    multitrack.binarize()\n",
        "    # Downsample the pianorolls (shape: n_timesteps x n_pitches)\n",
        "    multitrack.set_resolution(beat_resolution)\n",
        "    # Stack the pianoroll (shape: n_tracks x n_timesteps x n_pitches)\n",
        "    pianoroll = (multitrack.stack() > 0)\n",
        "    # Get the target pitch range only\n",
        "    pianoroll = pianoroll[:, :, lowest_pitch:lowest_pitch + n_pitches]\n",
        "    # Calculate the total measures\n",
        "    n_total_measures = multitrack.get_max_length() // measure_resolution\n",
        "    candidate = n_total_measures - n_measures\n",
        "    target_n_samples = min(n_total_measures // n_measures, n_samples_per_song)\n",
        "    # Randomly select a number of phrases from the multitrack pianoroll\n",
        "    for idx in np.random.choice(candidate, target_n_samples, False):\n",
        "        start = idx * measure_resolution\n",
        "        end = (idx + n_measures) * measure_resolution\n",
        "        # Skip the samples where some track(s) has too few notes\n",
        "        if (pianoroll.sum(axis=(1, 2)) < 10).any():\n",
        "            continue\n",
        "        data.append(pianoroll[:, start:end])\n",
        "# Stack all the collected pianoroll segments into one big array\n",
        "random.shuffle(data)\n",
        "data = np.stack(data)\n",
        "print(f\"Successfully collect {len(data)} samples from {len(id_list)} songs\")\n",
        "print(f\"Data shape : {data.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqpNtJFae4aF"
      },
      "source": [
        "### Visualize an example of training samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fkoP9rGgrLH"
      },
      "source": [
        "tracks = []\n",
        "for idx, (program, is_drum, track_name) in enumerate(zip(programs, is_drums, track_names)):\n",
        "    pianoroll = np.pad(\n",
        "        np.concatenate(data[:4], 1)[idx], ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches)))\n",
        "    tracks.append(Track(name=track_name, program=program, is_drum=is_drum, pianoroll=pianoroll))\n",
        "multitrack = Multitrack(tracks=tracks, tempo=tempo_array, resolution=beat_resolution)\n",
        "axs = multitrack.plot()\n",
        "plt.gcf().set_size_inches((16, 8))\n",
        "for ax in axs:\n",
        "    for x in range(measure_resolution, 4 * 4 * measure_resolution, measure_resolution):\n",
        "        if x % (measure_resolution * 4) == 0:\n",
        "            ax.axvline(x - 0.5, color='k')\n",
        "        else:\n",
        "            ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6fauic_H2wt"
      },
      "source": [
        "### Create dataset and data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBxjQEZFRhAK"
      },
      "source": [
        "data = torch.as_tensor(data, dtype=torch.float32)\n",
        "dataset = torch.utils.data.TensorDataset(data)\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=batch_size, drop_last=True, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94rrn1nmIQlG"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyX6Duf5fkiw"
      },
      "source": [
        " ### Define the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj9sCKbSKcse"
      },
      "source": [
        "class GeneraterBlock(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
        "        super().__init__()\n",
        "        self.transconv = torch.nn.ConvTranspose3d(in_dim, out_dim, kernel, stride)\n",
        "        self.batchnorm = torch.nn.BatchNorm3d(out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.transconv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        return torch.nn.functional.relu(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWPAxfkmsIWn"
      },
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    \"\"\"A convolutional neural network (CNN) based generator. The generator takes\n",
        "    as input a latent vector and outputs a fake sample.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.transconv0 = GeneraterBlock(latent_dim, 256, (4, 1, 1), (4, 1, 1))\n",
        "        self.transconv1 = GeneraterBlock(256, 128, (1, 4, 1), (1, 4, 1))\n",
        "        self.transconv2 = GeneraterBlock(128, 64, (1, 1, 4), (1, 1, 4))\n",
        "        self.transconv3 = GeneraterBlock(64, 32, (1, 1, 3), (1, 1, 1))\n",
        "        self.transconv4 = torch.nn.ModuleList([\n",
        "            GeneraterBlock(32, 16, (1, 4, 1), (1, 4, 1))\n",
        "            for _ in range(n_tracks)\n",
        "        ])\n",
        "        self.transconv5 = torch.nn.ModuleList([\n",
        "            GeneraterBlock(16, 1, (1, 1, 12), (1, 1, 12))\n",
        "            for _ in range(n_tracks)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, latent_dim, 1, 1, 1)\n",
        "        x = self.transconv0(x)\n",
        "        x = self.transconv1(x)\n",
        "        x = self.transconv2(x)\n",
        "        x = self.transconv3(x)\n",
        "        x = [transconv(x) for transconv in self.transconv4]\n",
        "        x = torch.cat([transconv(x_) for x_, transconv in zip(x, self.transconv5)], 1)\n",
        "        x = x.view(-1, n_tracks, n_measures * measure_resolution, n_pitches)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJPGeYNbfvw6"
      },
      "source": [
        " ### Define the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knw5u6Px2c8j"
      },
      "source": [
        "class LayerNorm(torch.nn.Module):\n",
        "    \"\"\"An implementation of Layer normalization that does not require size\n",
        "    information. Copied from https://github.com/pytorch/pytorch/issues/1959.\"\"\"\n",
        "    def __init__(self, n_features, eps=1e-5, affine=True):\n",
        "        super().__init__()\n",
        "        self.n_features = n_features\n",
        "        self.affine = affine\n",
        "        self.eps = eps\n",
        "        if self.affine:\n",
        "            self.gamma = torch.nn.Parameter(torch.Tensor(n_features).uniform_())\n",
        "            self.beta = torch.nn.Parameter(torch.zeros(n_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = [-1] + [1] * (x.dim() - 1)\n",
        "        mean = x.view(x.size(0), -1).mean(1).view(*shape)\n",
        "        std = x.view(x.size(0), -1).std(1).view(*shape)\n",
        "        y = (x - mean) / (std + self.eps)\n",
        "        if self.affine:\n",
        "            shape = [1, -1] + [1] * (x.dim() - 2)\n",
        "            y = self.gamma.view(*shape) * y + self.beta.view(*shape)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZhbO2jiFLG5"
      },
      "source": [
        "class DiscriminatorBlock(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
        "        super().__init__()\n",
        "        self.transconv = torch.nn.Conv3d(in_dim, out_dim, kernel, stride)\n",
        "        self.layernorm = LayerNorm(out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.transconv(x)\n",
        "        x = self.layernorm(x)\n",
        "        return torch.nn.functional.leaky_relu(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kczm8A8Nl78i"
      },
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "    \"\"\"A convolutional neural network (CNN) based discriminator. The\n",
        "    discriminator takes as input either a real sample (in the training data) or\n",
        "    a fake sample (generated by the generator) and outputs a scalar indicating\n",
        "    its authentity.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv0 = torch.nn.ModuleList([\n",
        "            DiscriminatorBlock(1, 16, (1, 1, 12), (1, 1, 12)) for _ in range(n_tracks)\n",
        "        ])\n",
        "        self.conv1 = torch.nn.ModuleList([\n",
        "            DiscriminatorBlock(16, 16, (1, 4, 1), (1, 4, 1)) for _ in range(n_tracks)\n",
        "        ])\n",
        "        self.conv2 = DiscriminatorBlock(16 * 5, 64, (1, 1, 3), (1, 1, 1))\n",
        "        self.conv3 = DiscriminatorBlock(64, 64, (1, 1, 4), (1, 1, 4))\n",
        "        self.conv4 = DiscriminatorBlock(64, 128, (1, 4, 1), (1, 4, 1))\n",
        "        self.conv5 = DiscriminatorBlock(128, 128, (2, 1, 1), (1, 1, 1))\n",
        "        self.conv6 = DiscriminatorBlock(128, 256, (3, 1, 1), (3, 1, 1))\n",
        "        self.dense = torch.nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, n_tracks, n_measures, measure_resolution, n_pitches)\n",
        "        x = [conv(x[:, [i]]) for i, conv in enumerate(self.conv0)]\n",
        "        x = torch.cat([conv(x_) for x_, conv in zip(x, self.conv1)], 1)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.dense(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiPl8DYCI7pC"
      },
      "source": [
        "## Training functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wngyfaaObas"
      },
      "source": [
        "def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n",
        "    \"\"\"Compute the gradient penalty for regularization. Intuitively, the\n",
        "    gradient penalty help stablize the magnitude of the gradients that the\n",
        "    discriminator provides to the generator, and thus help stablize the training\n",
        "    of the generator.\"\"\"\n",
        "    # Get random interpolations between real and fake samples\n",
        "    alpha = torch.rand(real_samples.size(0), 1, 1, 1).cuda()\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples))\n",
        "    interpolates = interpolates.requires_grad_(True)\n",
        "    # Get the discriminator output for the interpolations\n",
        "    d_interpolates = discriminator(interpolates)\n",
        "    # Get gradients w.r.t. the interpolations\n",
        "    fake = torch.ones(real_samples.size(0), 1).cuda()\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "    # Compute gradient penalty\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3mgXtVN8ldM"
      },
      "source": [
        "def train_one_step(d_optimizer, g_optimizer, real_samples):\n",
        "    \"\"\"Train the networks for one step.\"\"\"\n",
        "    # Sample from the lantent distribution\n",
        "    latent = torch.randn(batch_size, latent_dim)\n",
        "\n",
        "    # Transfer data to GPU\n",
        "    if torch.cuda.is_available():\n",
        "        real_samples = real_samples.cuda()\n",
        "        latent = latent.cuda()\n",
        "\n",
        "    # === Train the discriminator ===\n",
        "    # Reset cached gradients to zero\n",
        "    d_optimizer.zero_grad()\n",
        "    # Get discriminator outputs for the real samples\n",
        "    prediction_real = discriminator(real_samples)\n",
        "    # Compute the loss function\n",
        "    # d_loss_real = torch.mean(torch.nn.functional.relu(1. - prediction_real))\n",
        "    d_loss_real = -torch.mean(prediction_real)\n",
        "    # Backpropagate the gradients\n",
        "    d_loss_real.backward()\n",
        "\n",
        "    # Generate fake samples with the generator\n",
        "    fake_samples = generator(latent)\n",
        "    # Get discriminator outputs for the fake samples\n",
        "    prediction_fake_d = discriminator(fake_samples.detach())\n",
        "    # Compute the loss function\n",
        "    # d_loss_fake = torch.mean(torch.nn.functional.relu(1. + prediction_fake_d))\n",
        "    d_loss_fake = torch.mean(prediction_fake_d)\n",
        "    # Backpropagate the gradients\n",
        "    d_loss_fake.backward()\n",
        "\n",
        "    # Compute gradient penalty\n",
        "    gradient_penalty = 10.0 * compute_gradient_penalty(\n",
        "        discriminator, real_samples.data, fake_samples.data)\n",
        "    # Backpropagate the gradients\n",
        "    gradient_penalty.backward()\n",
        "\n",
        "    # Update the weights\n",
        "    d_optimizer.step()\n",
        "\n",
        "    # === Train the generator ===\n",
        "    # Reset cached gradients to zero\n",
        "    g_optimizer.zero_grad()\n",
        "    # Get discriminator outputs for the fake samples\n",
        "    prediction_fake_g = discriminator(fake_samples)\n",
        "    # Compute the loss function\n",
        "    g_loss = -torch.mean(prediction_fake_g)\n",
        "    # Backpropagate the gradients\n",
        "    g_loss.backward()\n",
        "    # Update the weights\n",
        "    g_optimizer.step()\n",
        "\n",
        "    return d_loss_real + d_loss_fake, g_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ukfh1dxIsDw"
      },
      "source": [
        "## Training Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCqTBe3p09xY"
      },
      "source": [
        "# Create data loader\n",
        "# data_loader = get_data_loader()\n",
        "\n",
        "# Create neural networks\n",
        "discriminator = Discriminator()\n",
        "generator = Generator()\n",
        "print(\"Number of parameters in G: {}\".format(\n",
        "    sum(p.numel() for p in generator.parameters() if p.requires_grad)))\n",
        "print(\"Number of parameters in D: {}\".format(\n",
        "    sum(p.numel() for p in discriminator.parameters() if p.requires_grad)))\n",
        "\n",
        "# Create optimizers\n",
        "d_optimizer = torch.optim.Adam(\n",
        "    discriminator.parameters(), lr=0.001,  betas=(0.5, 0.9))\n",
        "g_optimizer = torch.optim.Adam(\n",
        "    generator.parameters(), lr=0.001, betas=(0.5, 0.9))\n",
        "\n",
        "# Prepare the inputs for the sampler, which wil run during the training\n",
        "sample_latent = torch.randn(n_samples, latent_dim)\n",
        "\n",
        "# Transfer the neural nets and samples to GPU\n",
        "if torch.cuda.is_available():\n",
        "    discriminator = discriminator.cuda()\n",
        "    generator = generator.cuda()\n",
        "    sample_latent = sample_latent.cuda()\n",
        "\n",
        "# Create an empty dictionary to sotre history samples\n",
        "history_samples = {}\n",
        "\n",
        "# Create a LiveLoss logger instance for monitoring\n",
        "liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6,2))])\n",
        "\n",
        "# Initialize step\n",
        "step = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL499fTNJcSd"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsCO34_A3N2U"
      },
      "source": [
        "# Create a progress bar instance for monitoring\n",
        "progress_bar = tqdm(total=n_steps, initial=step, ncols=80, mininterval=1)\n",
        "\n",
        "# Start iterations\n",
        "while step < n_steps + 1:\n",
        "    # Iterate over the dataset\n",
        "    for real_samples in data_loader:\n",
        "        # Train the neural networks\n",
        "        generator.train()\n",
        "        d_loss, g_loss = train_one_step(d_optimizer, g_optimizer, real_samples[0])\n",
        "\n",
        "        # Record smoothened loss values to LiveLoss logger\n",
        "        if step > 0:\n",
        "            running_d_loss = 0.05 * d_loss + 0.95 * running_d_loss\n",
        "            running_g_loss = 0.05 * g_loss + 0.95 * running_g_loss\n",
        "        else:\n",
        "            running_d_loss, running_g_loss = 0.0, 0.0\n",
        "        liveloss.update({'negative_critic_loss': -running_d_loss})\n",
        "        # liveloss.update({'d_loss': running_d_loss, 'g_loss': running_g_loss})\n",
        "\n",
        "        # Update losses to progress bar\n",
        "        progress_bar.set_description_str(\n",
        "            \"(d_loss={: 8.6f}, g_loss={: 8.6f})\".format(d_loss, g_loss))\n",
        "\n",
        "        if step % sample_interval == 0:\n",
        "            # Get generated samples\n",
        "            generator.eval()\n",
        "            samples = generator(sample_latent).cpu().detach().numpy()\n",
        "            history_samples[step] = samples\n",
        "\n",
        "            # Display loss curves\n",
        "            clear_output(True)\n",
        "            if step > 0:\n",
        "                liveloss.send()\n",
        "\n",
        "            # Display generated samples\n",
        "            samples = samples.transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)\n",
        "            tracks = []\n",
        "            for idx, (program, is_drum, track_name) in enumerate(\n",
        "                zip(programs, is_drums, track_names)\n",
        "            ):\n",
        "                pianoroll = np.pad(\n",
        "                    samples[idx] > 0.5,\n",
        "                    ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))\n",
        "                )\n",
        "                tracks.append(\n",
        "                    Track(\n",
        "                        name=track_name,\n",
        "                        program=program,\n",
        "                        is_drum=is_drum,\n",
        "                        pianoroll=pianoroll\n",
        "                    )\n",
        "                )\n",
        "            m = Multitrack(\n",
        "                tracks=tracks,\n",
        "                tempo=tempo_array,\n",
        "                resolution=beat_resolution\n",
        "            )\n",
        "            axs = m.plot()\n",
        "            plt.gcf().set_size_inches((16, 8))\n",
        "            for ax in axs:\n",
        "                for x in range(\n",
        "                    measure_resolution,\n",
        "                    4 * measure_resolution * n_measures,\n",
        "                    measure_resolution\n",
        "                ):\n",
        "                    if x % (measure_resolution * 4) == 0:\n",
        "                        ax.axvline(x - 0.5, color='k')\n",
        "                    else:\n",
        "                        ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)\n",
        "            plt.show()\n",
        "\n",
        "        step += 1\n",
        "        progress_bar.update(1)\n",
        "        if step >= n_steps:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjX855uYf6sC"
      },
      "source": [
        "## Training History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqN1sKoODaCm"
      },
      "source": [
        "# Show history\n",
        "steps = [0, sample_interval, 10 * sample_interval, 100 * sample_interval, n_steps]\n",
        "for step in steps:\n",
        "    print(f\"Step={step}\")\n",
        "    samples = history_samples[step].transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)\n",
        "    tracks = []\n",
        "    for idx, (program, is_drum, track_name) in enumerate(zip(programs, is_drums, track_names)):\n",
        "        pianoroll = np.pad(\n",
        "            samples[idx] > 0.5,\n",
        "            ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))\n",
        "        )\n",
        "        tracks.append(\n",
        "            Track(\n",
        "                name=track_name,\n",
        "                program=program,\n",
        "                is_drum=is_drum,\n",
        "                pianoroll=pianoroll,\n",
        "            )\n",
        "        )\n",
        "    m = Multitrack(tracks=tracks, tempo=tempo_array, resolution=beat_resolution)\n",
        "    axs = m.plot()\n",
        "    for ax in axs:\n",
        "        for x in range(\n",
        "            measure_resolution,\n",
        "            4 * measure_resolution * n_measures,\n",
        "            measure_resolution\n",
        "        ):\n",
        "            if x % (measure_resolution * 4) == 0:\n",
        "                ax.axvline(x - 0.5, color='k')\n",
        "            else:\n",
        "                ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)\n",
        "    plt.gcf().set_size_inches((16, 8))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeJpOeUXjdBu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}